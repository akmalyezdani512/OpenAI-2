{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qm8x2zhhd-8"
      },
      "source": [
        "# Integrating tools/function with LLM using Azure OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu6uxcLphsRz",
        "outputId": "dcee60be-8dfc-4600-e9e7-a89b5f7b163d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GTT0Jc-qhVby"
      },
      "outputs": [],
      "source": [
        "api_key = \"xxxxxxxxxxxxx\"\n",
        "api_version = \"2023-07-01-preview\" # \"2023-05-15\"\n",
        "azure_endpoint = \"https://xxxxxxxxx.openai.azure.com/\"\n",
        "model_name = \"gpt-4o\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PLKRALkuhVby"
      },
      "outputs": [],
      "source": [
        "from openai import AzureOpenAI\n",
        "import json\n",
        "import requests\n",
        "\n",
        "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
        "client = AzureOpenAI(\n",
        "    # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\n",
        "    api_version=api_version,\n",
        "    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    api_key = api_key,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMs1SliPer2Q"
      },
      "source": [
        "In an API call, you can describe functions and have the model intelligently choose to output a JSON object containing arguments to call one or many functions. The Chat Completions API does not call the function; instead, the model generates JSON that you can use to call the function in your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6voT6dEZOEQ"
      },
      "source": [
        "## Supported models\n",
        "Not all model versions are trained with function calling data. Function calling is supported with the following models: gpt-4, gpt-4-turbo-preview, gpt-4-0125-preview, gpt-4-1106-preview, gpt-4-0613, gpt-3.5-turbo, gpt-3.5-turbo-0125, gpt-3.5-turbo-1106, and gpt-3.5-turbo-0613\n",
        "\n",
        "In addition, parallel function calls is supported on the following models: gpt-4-turbo-preview, gpt-4-0125-preview, gpt-4-1106-preview, gpt-3.5-turbo-0125, and gpt-3.5-turbo-1106"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "107aABFoiI6R"
      },
      "outputs": [],
      "source": [
        "# Example function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    if \"tokyo\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
        "    elif \"san francisco\" in location.lower():\n",
        "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
        "    elif \"paris\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
        "    else:\n",
        "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FUAVQTH1FCob"
      },
      "outputs": [],
      "source": [
        "owm_api = \"29af1cea50a401d8e624eea4660b3f59\"\n",
        "\n",
        "# create a dummy function to respond temperature\n",
        "def get_current_weather2(location, unit=\"fahrenheit\"):\n",
        "  \"This function can be used to fetch the current weather information when provided with details such as location and unit for temperature\"\n",
        "\n",
        "  url = f\"https://api.openweathermap.org/data/2.5/weather?q={location}&appid={owm_api}\"\n",
        "  response = requests.get(url)\n",
        "  temp = response.json()['main']['temp']\n",
        "  forecast = [response.json()['weather'][0]['main'],response.json()['weather'][0]['description']]\n",
        "\n",
        "  weather_info = {\n",
        "      \"location\":location,\n",
        "      \"temperature\":temp,\n",
        "      \"unit\":'Kelvin',\n",
        "      \"forecast\":forecast\n",
        "  }\n",
        "  return json.dumps(weather_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zvpewsATGB30",
        "outputId": "01d29cea-3467-4fc5-b124-8f38b473468f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"fahrenheit\"}'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_current_weather(\"Paris\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sTPInk2CiVpV",
        "outputId": "bbd31641-53d2-4f91-d578-9d5ec50c4e03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"location\": \"Manila\", \"temperature\": 301.42, \"unit\": \"Kelvin\", \"forecast\": [\"Clouds\", \"scattered clouds\"]}'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_current_weather2(\"Manila\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OLj1VFabUCR",
        "outputId": "cb038e0a-fc95-4c8f-9f14-f783a84f494e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletionMessage(content=\"Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are designed to think and act like humans. These systems are able to perform tasks that typically require human intelligence, including understanding natural language, recognizing patterns, solving problems, and making decisions. AI can be categorized into various types based on its capabilities:\\n\\n1. **Narrow AI (Weak AI)**: This type of AI is designed to perform a specific task or a narrow range of tasks. Examples include virtual assistants like Siri or Alexa, recommendation systems on Netflix, and self-driving car technologies. Narrow AI operates under a limited set of constraints and parameters.\\n\\n2. **General AI (Strong AI)**: This is still theoretical and represents AI systems that possess the ability to understand, learn, and apply knowledge in a way that is indistinguishable from human cognitive abilities. General AI would be capable of performing any intellectual task that a human can, across various domains and disciplines.\\n\\n3. **Superintelligent AI**: This is a hypothetical future AI which surpasses human intelligence across all fields and can perform tasks better than humans at every possible cognitive task.\\n\\nAI applications span many areas including healthcare, finance, education, entertainment, and transportation. Common techniques used in AI include:\\n\\n- **Machine Learning (ML)**: A subset of AI that enables systems to learn and improve from experience without being explicitly programmed. It includes various approaches like supervised learning, unsupervised learning, and reinforcement learning.\\n  \\n- **Deep Learning**: A subset of ML that uses neural networks with many layers (deep neural networks) to analyze various factors of data. Highly effective in image and speech recognition.\\n\\n- **Natural Language Processing (NLP)**: Enables machines to understand and respond to human language. It's used in applications like chatbots, translation services, and sentiment analysis.\\n\\n- **Computer Vision**: Allows machines to interpret and make decisions based on visual inputs from the world. It's used in facial recognition, autonomous vehicles, and medical image analysis.\\n\\nOverall, AI aims to enhance or replicate human abilities through the use of computational methods, thereby performing tasks more efficiently, accurately, and tirelessly than human counterparts can in some cases.\", role='assistant', function_call=None, tool_calls=None)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = [{\"role\":\"user\",'content':\"what is AI?\"}]\n",
        "results = client.chat.completions.create(model = model_name, messages = messages)\n",
        "results.choices[0].message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9gdvGUJGbheA"
      },
      "outputs": [],
      "source": [
        "tools = [{\n",
        "                            \"type\":\"function\",\n",
        "                            \"function\":{\"name\": \"get_current_weather\",\n",
        "                           \"description\": \"This function can be used to fetch the current weather information when provided with details such as location and unit for temperature\",\n",
        "                           \"parameters\": {\n",
        "                               \"type\": \"object\",\n",
        "                               \"properties\": {\"location\": {\n",
        "                                   \"type\": \"string\",\n",
        "                                   \"description\": \"The name of city/state/country for which weather information is to be fetched\",},},\n",
        "                               \"required\": [\"location\",],},},}]\n",
        "\n",
        "\n",
        "\n",
        "def get_response(messages, tools,model=model_name):\n",
        "  response = client.chat.completions.create(model = model, messages = messages, tools=tools, tool_choice='auto', temperature=0.5,)\n",
        "  response = response.choices[0].message\n",
        "  tool_calls = response.tool_calls\n",
        "\n",
        "  try:\n",
        "    if tool_calls:\n",
        "      print(\"Making a function call\")\n",
        "      # get available functions\n",
        "      available_functions = {\n",
        "          \"get_current_weather\":get_current_weather,\n",
        "      }\n",
        "      print(tool_calls)\n",
        "\n",
        "      # get details to call the function assuming there is only one function call\n",
        "      func_name = tool_calls[0].function.name\n",
        "      func_to_call = available_functions[func_name]\n",
        "      func_args = json.loads(tool_calls[0].function.arguments)\n",
        "\n",
        "      # call the external api by calling the function\n",
        "      func_response = func_to_call(**func_args)\n",
        "\n",
        "      # again make a call to openai api to communicate results from external function/API\n",
        "      messages.append(response)\n",
        "      messages.append(\n",
        "          {\"tool_call_id\":tool_calls[0].id,\n",
        "          \"role\":\"tool\",\n",
        "          \"name\":func_name,\n",
        "          \"content\":str(func_response)}\n",
        "      )\n",
        "\n",
        "      second_response = client.chat.completions.create(\n",
        "      model = model_name,\n",
        "      messages = messages)\n",
        "      return second_response\n",
        "    else:\n",
        "      return response.content\n",
        "  except Exception as e:\n",
        "      print(\"Error occurred \",e)\n",
        "      return response\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWL0wVqFdeBm",
        "outputId": "af1791a3-7e05-4527-e75e-9caefe8bd685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It involves various technologies and algorithms that enable computers to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation.\n"
          ]
        }
      ],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"Provide a 2 line explanation for AI\"}]\n",
        "response = get_response(messages, tools)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0H4DaivdmPW",
        "outputId": "67d2c2f0-8be3-41c2-aee4-7f115fadf366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Making a function call\n",
            "[ChatCompletionMessageToolCall(id='call_NP0ZCZ1TH7HKXLsFohGJ60HY', function=Function(arguments='{\"location\":\"Tokyo\"}', name='get_current_weather'), type='function')]\n",
            "The current temperature in Tokyo is 10°F. If you need more detailed information such as humidity, wind speed, or weather conditions, please let me know!\n"
          ]
        }
      ],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"How is the weather in Tokyo today?\"}]\n",
        "response = get_response(messages, tools)\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxTpMV2ZczHs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
