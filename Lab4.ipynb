{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jlaZEpkfgIw"
      },
      "source": [
        "# Image Generation with DALLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgRNVrPRCKW3"
      },
      "source": [
        "#1.chat completion  \n",
        " Here we are generating Texts,so that we are going to use client.chat.completions.create().\n",
        "So We are creating Text, so we can think as for text we use 'chat' and generation we use 'create()' after completions in client.chat.completions.create()\n",
        "\n",
        "Now create has various parameters like model,messages,temperature,top_p,n,stream,presence_penalty,frequency_penalty\n",
        "\n",
        "Let's understand the important parameters\n",
        "\n",
        "\"messages\":This will contain the conversation or query which you want to ask to openai chat model.\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "temperature:Temperature is a parameter that controls the “creativity” or randomness of the text generated by GPT,It's value ranges from 0 to 2.\n",
        "\n",
        "A higher temperature (e.g., 0.7) results in more diverse and creative output, while a lower temperature (e.g., 0.2) makes the output more deterministic and focused.\n",
        "\n",
        "\"model\":you need to define any openai GPT chat models which work is to chat or answer the asked question, some openai GPT chat models like gpt-3.5-turbo,gpt-4, gpt-4 turbo.\n",
        "for using the chatcompletion we can use these models also\n",
        "(1)gpt-3.5-turbo-0613\n",
        "(2)gpt-3.5-turbo-0301\n",
        "(3)gpt-4-0314\n",
        "(4)gpt-4-32k-0314"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noWGU51bCTBF",
        "outputId": "d33a82ac-9bb6-477f-f7e4-eb90135a4609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/324.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m317.4/324.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"ed1a587475b74a178e4da9f49c27839e\"\n",
        "api_version = \"2023-07-01-preview\" # \"2023-05-15\"\n",
        "azure_endpoint = \"https://anshugpt.openai.azure.com/\"\n",
        "model_name = \"dall-e-3\""
      ],
      "metadata": {
        "id": "WckDHzlHqm-0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PLKRALkuhVby"
      },
      "outputs": [],
      "source": [
        "from openai import AzureOpenAI\n",
        "\n",
        "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
        "client = AzureOpenAI(\n",
        "    # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\n",
        "    api_version=api_version,\n",
        "    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    api_key = api_key,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTy5iLp_ICYx"
      },
      "source": [
        "#  Image Generation using OpenAI's DALL-E\n",
        "\n",
        "\n",
        "In this example, we are using OpenAI's DALL-E model to generate an image based on a text prompt.\n",
        "\n",
        "Here we are generating Texts,so that we are going to use client.images.generate(). So We are creating Images, so we can think as for image we use 'images' and generation we use 'generate()' after completions in client.images.generate()\n",
        "\n",
        "The process involves using the OpenAI API to interact with the DALL-E model.\n",
        "\n",
        "This exploration into DALL-E's capabilities offers a glimpse into the cutting-edge advancements in AI, illustrating the exciting potential for creative applications and innovative content creation.\n",
        "\n",
        "Here we are using DALL-E-3 but we can also use DALL-E-2 for image generation,we just need to specify \"dall-e-2\" to model parameter.\n",
        "\n",
        "When using DALL·E 3, images can have a size of 1024x1024, 1024x1792 or 1792x1024 pixels.But we can generate lower resolution image in DALL.E 2\n",
        "\n",
        "By default, images are generated at standard quality, but when using DALL·E 3 you can set quality: \"hd\" for enhanced detail.\n",
        "\n",
        "You can request 1 image at a time with DALL·E 3 (request more by making parallel requests) or up to 10 images at a time using DALL·E 2 with the n parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUsZLfgJ7FS_"
      },
      "source": [
        "# Image generation using Dalle-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "OCDvDa4hNRWw",
        "outputId": "ef8e06b4-d0c2-48ea-c36c-a1492c06f9aa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e086f436dfc2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a client object for the OpenAI API and provide your API key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response2 = client.images.generate(\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dall-e-3\"\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# Specify the DALL-E 3 model to use, you can also use dall-e-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" An expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula.\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Provide a text prompt for generating the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1024x1024\"\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# Specify the desired size of the generated image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/images.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompt, model, n, quality, response_format, size, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    254\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m--> 256\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0;34m\"/images/generations\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         )\n\u001b[0;32m-> 1240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 921\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    922\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}"
          ]
        }
      ],
      "source": [
        "# Create a client object for the OpenAI API and provide your API key\n",
        "response2 = client.images.generate(\n",
        "  model=\"dall-e-3\",           # Specify the DALL-E 3 model to use, you can also use dall-e-2\n",
        "  prompt=\" An expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula.\",  # Provide a text prompt for generating the image\n",
        "  size=\"1024x1024\",           # Specify the desired size of the generated image\n",
        "  quality=\"standard\",         # Specify the quality level of the generated image(standard,hd,square)\n",
        "  n=1,                        # Specify the number of images to generate (in this case, 1)\n",
        ")\n",
        "\n",
        "# Extract the URL of the generated image from the response\n",
        "image_urls = response2.data[0].url\n",
        "image_urls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zkXttMhZRcRe",
        "outputId": "6e8d4abd-1191-4d31-ce7f-1d4ed9c697af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-UTPW1zcMiNHrsEBoeWR8ibdh/user-H18YKM9xhcAYzaDJLsxq9OIM/img-Dlr1IoC9Lw5uw5uTm0lcUBlD.png?st=2024-05-12T01%3A32%3A32Z&se=2024-05-12T03%3A32%3A32Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-11T22%3A22%3A02Z&ske=2024-05-12T22%3A22%3A02Z&sks=b&skv=2021-08-06&sig=rydUhzIwBR4i%2BdVD3gZeVg3vkk8xuAVJfryWU5xSWsE%3D\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Use the image_url obtained from your DALL-E generation code\n",
        "image_url = image_urls\n",
        "# Display the image in the output cell\n",
        "display(Image(url=image_url))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thank You"
      ],
      "metadata": {
        "id": "_mWMYxCRp9d3"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}